{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/V-Lamba/Rock_vs_Mine-Predictor/blob/main/Rock_vs_Mine_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem is to predict metal or rock objects from sonar return data. Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time."
      ],
      "metadata": {
        "id": "AbrACK5wY4-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to cover the following steps:\n",
        "\n",
        "Load the Dataset (Import libraries and Load dataset)\n",
        "\n",
        "Analyze Data (Descriptive Statistics)\n",
        "\n",
        "Splitting the dataset into the Training set and Test set\n",
        "\n",
        "Evaluate Algorithms: Baseline\n",
        "\n",
        "Algorithm Tuning\n",
        "\n",
        "Finalize Model based on selecting Best method\n",
        "\n"
      ],
      "metadata": {
        "id": "cUhEna2oZPZf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYSLvRgB3Sel"
      },
      "source": [
        "# **Load the Dataset (Import libraries and Load dataset)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbE3ZjDb23el"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ymxgj2i3RwO"
      },
      "source": [
        "#loading the dataset to a pandas Dataframe\n",
        "sonar_data = pd.read_csv('/content/sonar data.csv', header=None) # as we don't have any header names for the columns so put header=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyze Data (Descriptive Statistics)**"
      ],
      "metadata": {
        "id": "gYZ9zioXhiBI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "I5iWxSnM42fl",
        "outputId": "a323cf2c-37d6-4084-b9cf-24d43360010f"
      },
      "source": [
        "sonar_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   R  \n",
              "1  0.0052  0.0044   R  \n",
              "2  0.0095  0.0078   R  \n",
              "3  0.0040  0.0117   R  \n",
              "4  0.0107  0.0094   R  \n",
              "\n",
              "[5 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eed6e06c-a320-49b8-9385-494d8ae1228b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eed6e06c-a320-49b8-9385-494d8ae1228b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eed6e06c-a320-49b8-9385-494d8ae1228b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eed6e06c-a320-49b8-9385-494d8ae1228b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN_FI_eN48V_",
        "outputId": "d4d6d3f5-29d1-493c-87a2-c6cc742e88f0"
      },
      "source": [
        "# number of rows and columns\n",
        "sonar_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(208, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "q6A1r9J-5aOJ",
        "outputId": "6b5d37c3-5c7a-4791-b959-77373f62853e"
      },
      "source": [
        "sonar_data.describe()  #describe --> statistical measures of the data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0           1           2           3           4           5   \\\n",
              "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
              "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
              "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
              "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
              "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
              "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
              "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
              "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
              "\n",
              "               6           7           8           9   ...          50  \\\n",
              "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
              "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
              "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
              "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
              "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
              "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
              "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
              "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
              "\n",
              "               51          52          53          54          55          56  \\\n",
              "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
              "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
              "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
              "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
              "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
              "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
              "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
              "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
              "\n",
              "               57          58          59  \n",
              "count  208.000000  208.000000  208.000000  \n",
              "mean     0.007949    0.007941    0.006507  \n",
              "std      0.006470    0.006181    0.005031  \n",
              "min      0.000300    0.000100    0.000600  \n",
              "25%      0.003600    0.003675    0.003100  \n",
              "50%      0.005800    0.006400    0.005300  \n",
              "75%      0.010350    0.010325    0.008525  \n",
              "max      0.044000    0.036400    0.043900  \n",
              "\n",
              "[8 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed835c4e-4ac1-4674-b326-f94f49082ae3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.029164</td>\n",
              "      <td>0.038437</td>\n",
              "      <td>0.043832</td>\n",
              "      <td>0.053892</td>\n",
              "      <td>0.075202</td>\n",
              "      <td>0.104570</td>\n",
              "      <td>0.121747</td>\n",
              "      <td>0.134799</td>\n",
              "      <td>0.178003</td>\n",
              "      <td>0.208259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016069</td>\n",
              "      <td>0.013420</td>\n",
              "      <td>0.010709</td>\n",
              "      <td>0.010941</td>\n",
              "      <td>0.009290</td>\n",
              "      <td>0.008222</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.007941</td>\n",
              "      <td>0.006507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.022991</td>\n",
              "      <td>0.032960</td>\n",
              "      <td>0.038428</td>\n",
              "      <td>0.046528</td>\n",
              "      <td>0.055552</td>\n",
              "      <td>0.059105</td>\n",
              "      <td>0.061788</td>\n",
              "      <td>0.085152</td>\n",
              "      <td>0.118387</td>\n",
              "      <td>0.134416</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012008</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.007301</td>\n",
              "      <td>0.007088</td>\n",
              "      <td>0.005736</td>\n",
              "      <td>0.005785</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.006181</td>\n",
              "      <td>0.005031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.013350</td>\n",
              "      <td>0.016450</td>\n",
              "      <td>0.018950</td>\n",
              "      <td>0.024375</td>\n",
              "      <td>0.038050</td>\n",
              "      <td>0.067025</td>\n",
              "      <td>0.080900</td>\n",
              "      <td>0.080425</td>\n",
              "      <td>0.097025</td>\n",
              "      <td>0.111275</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008425</td>\n",
              "      <td>0.007275</td>\n",
              "      <td>0.005075</td>\n",
              "      <td>0.005375</td>\n",
              "      <td>0.004150</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.003675</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.034300</td>\n",
              "      <td>0.044050</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.092150</td>\n",
              "      <td>0.106950</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.152250</td>\n",
              "      <td>0.182400</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013900</td>\n",
              "      <td>0.011400</td>\n",
              "      <td>0.009550</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.006850</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.035550</td>\n",
              "      <td>0.047950</td>\n",
              "      <td>0.057950</td>\n",
              "      <td>0.064500</td>\n",
              "      <td>0.100275</td>\n",
              "      <td>0.134125</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.169600</td>\n",
              "      <td>0.233425</td>\n",
              "      <td>0.268700</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020825</td>\n",
              "      <td>0.016725</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>0.010425</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.010325</td>\n",
              "      <td>0.008525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.233900</td>\n",
              "      <td>0.305900</td>\n",
              "      <td>0.426400</td>\n",
              "      <td>0.401000</td>\n",
              "      <td>0.382300</td>\n",
              "      <td>0.372900</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>0.682800</td>\n",
              "      <td>0.710600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100400</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.039000</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.039400</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 60 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed835c4e-4ac1-4674-b326-f94f49082ae3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed835c4e-4ac1-4674-b326-f94f49082ae3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed835c4e-4ac1-4674-b326-f94f49082ae3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFlxfDyk5o00",
        "outputId": "7e1f6d02-13d3-4005-a12d-38a762cde0c8"
      },
      "source": [
        "sonar_data[60].value_counts() # in column ,111 data enteries for rock and 97 enteries for sonar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    111\n",
              "R     97\n",
              "Name: 60, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6RDFTc26aBI"
      },
      "source": [
        "M --> Mine\n",
        "\n",
        "R --> Rock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Uis1XlFs6M09",
        "outputId": "bb0dd37e-f8be-4b62-d766-5be723ac55d7"
      },
      "source": [
        "sonar_data.groupby(60).mean() # mean values for all the columns for mine and rock separately"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6   \\\n",
              "60                                                                         \n",
              "M   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \n",
              "R   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n",
              "\n",
              "          7         8         9   ...        50        51        52        53  \\\n",
              "60                                ...                                           \n",
              "M   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \n",
              "R   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n",
              "\n",
              "          54        55        56        57        58        59  \n",
              "60                                                              \n",
              "M   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \n",
              "R   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n",
              "\n",
              "[2 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-518488ea-e5a6-4f83-8501-f2ef4f423be5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>0.034989</td>\n",
              "      <td>0.045544</td>\n",
              "      <td>0.050720</td>\n",
              "      <td>0.064768</td>\n",
              "      <td>0.086715</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>0.128359</td>\n",
              "      <td>0.149832</td>\n",
              "      <td>0.213492</td>\n",
              "      <td>0.251022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019352</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>0.011643</td>\n",
              "      <td>0.012185</td>\n",
              "      <td>0.009923</td>\n",
              "      <td>0.008914</td>\n",
              "      <td>0.007825</td>\n",
              "      <td>0.009060</td>\n",
              "      <td>0.008695</td>\n",
              "      <td>0.006930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R</th>\n",
              "      <td>0.022498</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.035951</td>\n",
              "      <td>0.041447</td>\n",
              "      <td>0.062028</td>\n",
              "      <td>0.096224</td>\n",
              "      <td>0.114180</td>\n",
              "      <td>0.117596</td>\n",
              "      <td>0.137392</td>\n",
              "      <td>0.159325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012311</td>\n",
              "      <td>0.010453</td>\n",
              "      <td>0.009640</td>\n",
              "      <td>0.009518</td>\n",
              "      <td>0.008567</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.007814</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>0.007078</td>\n",
              "      <td>0.006024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 60 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-518488ea-e5a6-4f83-8501-f2ef4f423be5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-518488ea-e5a6-4f83-8501-f2ef4f423be5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-518488ea-e5a6-4f83-8501-f2ef4f423be5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRShuFc46jLd"
      },
      "source": [
        "# separating data and Labels\n",
        "X = sonar_data.drop(columns=60, axis=1) # for dropping a column we write axis as 1 , for dropping a row we write axis as 0\n",
        "Y = sonar_data[60]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkRRrxIe7D7l",
        "outputId": "7b4d41d1-1abb-4a47-c807-2ec697ab42de"
      },
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0       1       2       3       4       5       6       7       8   \\\n",
            "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
            "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
            "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
            "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
            "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
            "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
            "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
            "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
            "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
            "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
            "\n",
            "         9   ...      50      51      52      53      54      55      56  \\\n",
            "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
            "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
            "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
            "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
            "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
            "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
            "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
            "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
            "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
            "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
            "\n",
            "         57      58      59  \n",
            "0    0.0084  0.0090  0.0032  \n",
            "1    0.0049  0.0052  0.0044  \n",
            "2    0.0164  0.0095  0.0078  \n",
            "3    0.0044  0.0040  0.0117  \n",
            "4    0.0048  0.0107  0.0094  \n",
            "..      ...     ...     ...  \n",
            "203  0.0115  0.0193  0.0157  \n",
            "204  0.0032  0.0062  0.0067  \n",
            "205  0.0138  0.0077  0.0031  \n",
            "206  0.0079  0.0036  0.0048  \n",
            "207  0.0036  0.0061  0.0115  \n",
            "\n",
            "[208 rows x 60 columns]\n",
            "0      R\n",
            "1      R\n",
            "2      R\n",
            "3      R\n",
            "4      R\n",
            "      ..\n",
            "203    M\n",
            "204    M\n",
            "205    M\n",
            "206    M\n",
            "207    M\n",
            "Name: 60, Length: 208, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j912DrKe7L03"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTnEFld87GIr"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, stratify=Y, random_state=1) #stratify=Y , we needn to split the data based on rock and mine ... say for ex we need to have equal number/percentage  of rocks in tested , training data and equal number of mines in training, testing data as we have the original one."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww4D1Ps379_h",
        "outputId": "0f216c09-d2db-4f53-8c0c-9c36ef94dc6f"
      },
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 60) (187, 60) (21, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBvcm4eR8enA",
        "outputId": "a14f7329-bf88-446e-99e6-3421731c25b6"
      },
      "source": [
        "print(X_train)\n",
        "print(Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0       1       2       3       4       5       6       7       8   \\\n",
            "115  0.0414  0.0436  0.0447  0.0844  0.0419  0.1215  0.2002  0.1516  0.0818   \n",
            "38   0.0123  0.0022  0.0196  0.0206  0.0180  0.0492  0.0033  0.0398  0.0791   \n",
            "56   0.0152  0.0102  0.0113  0.0263  0.0097  0.0391  0.0857  0.0915  0.0949   \n",
            "123  0.0270  0.0163  0.0341  0.0247  0.0822  0.1256  0.1323  0.1584  0.2017   \n",
            "18   0.0270  0.0092  0.0145  0.0278  0.0412  0.0757  0.1026  0.1138  0.0794   \n",
            "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "140  0.0412  0.1135  0.0518  0.0232  0.0646  0.1124  0.1787  0.2407  0.2682   \n",
            "5    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
            "154  0.0117  0.0069  0.0279  0.0583  0.0915  0.1267  0.1577  0.1927  0.2361   \n",
            "131  0.1150  0.1163  0.0866  0.0358  0.0232  0.1267  0.2417  0.2661  0.4346   \n",
            "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
            "\n",
            "         9   ...      50      51      52      53      54      55      56  \\\n",
            "115  0.1975  ...  0.0222  0.0045  0.0136  0.0113  0.0053  0.0165  0.0141   \n",
            "38   0.0475  ...  0.0149  0.0125  0.0134  0.0026  0.0038  0.0018  0.0113   \n",
            "56   0.1504  ...  0.0048  0.0049  0.0041  0.0036  0.0013  0.0046  0.0037   \n",
            "123  0.2122  ...  0.0197  0.0189  0.0204  0.0085  0.0043  0.0092  0.0138   \n",
            "18   0.1520  ...  0.0045  0.0084  0.0010  0.0018  0.0068  0.0039  0.0120   \n",
            "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "140  0.2058  ...  0.0798  0.0376  0.0143  0.0272  0.0127  0.0166  0.0095   \n",
            "5    0.3039  ...  0.0104  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057   \n",
            "154  0.2169  ...  0.0039  0.0053  0.0029  0.0020  0.0013  0.0029  0.0020   \n",
            "131  0.5378  ...  0.0228  0.0099  0.0065  0.0085  0.0166  0.0110  0.0190   \n",
            "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
            "\n",
            "         57      58      59  \n",
            "115  0.0077  0.0246  0.0198  \n",
            "38   0.0058  0.0047  0.0071  \n",
            "56   0.0011  0.0034  0.0033  \n",
            "123  0.0094  0.0105  0.0093  \n",
            "18   0.0132  0.0070  0.0088  \n",
            "..      ...     ...     ...  \n",
            "140  0.0225  0.0098  0.0085  \n",
            "5    0.0027  0.0051  0.0062  \n",
            "154  0.0062  0.0026  0.0052  \n",
            "131  0.0141  0.0068  0.0086  \n",
            "203  0.0115  0.0193  0.0157  \n",
            "\n",
            "[187 rows x 60 columns]\n",
            "115    M\n",
            "38     R\n",
            "56     R\n",
            "123    M\n",
            "18     R\n",
            "      ..\n",
            "140    M\n",
            "5      R\n",
            "154    M\n",
            "131    M\n",
            "203    M\n",
            "Name: 60, Length: 187, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Algorithms: Baseline"
      ],
      "metadata": {
        "id": "yQ3iEcdctlb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't know what algorithms will do well on this dataset.We will use 10-fold cross validation. The dataset is not too small and this is a good standard test harness configuration. We will evaluate algorithms using the accuracy metric. This is a gross metric that will give a quick idea of how correct a given model is. More useful on binary classification problems like this one."
      ],
      "metadata": {
        "id": "c9YB1nTBtvIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame()\n",
        "predictions_df['action']=Y_test"
      ],
      "metadata": {
        "id": "i_hRZTsAAID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spot-Check Algorithms\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('SVM', SVC()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('DTC', DecisionTreeClassifier()))\n",
        "models.append(('RFT', RandomForestClassifier()))"
      ],
      "metadata": {
        "id": "LlE9Eq_etsMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=10) # on training data set\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    print('K-fold cross validation score->')\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "    model.fit(X_train, Y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions_df[name.strip(\":\")]=y_pred\n",
        "    test_data_accuracy = accuracy_score(y_pred, Y_test)\n",
        "    print(\"model's accuracy score on the test data  :\" , test_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELOdR1nUuT61",
        "outputId": "0c0adcff-e5b5-46b1-9415-98ac71bf4093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold cross validation score->\n",
            "LR: 0.759064 (0.077053)\n",
            "model's accuracy score on the test data  : 0.7619047619047619\n",
            "K-fold cross validation score->\n",
            "KNN: 0.775439 (0.084318)\n",
            "model's accuracy score on the test data  : 0.8095238095238095\n",
            "K-fold cross validation score->\n",
            "SVM: 0.801462 (0.089956)\n",
            "model's accuracy score on the test data  : 0.8095238095238095\n",
            "K-fold cross validation score->\n",
            "NB: 0.711696 (0.142888)\n",
            "model's accuracy score on the test data  : 0.6190476190476191\n",
            "K-fold cross validation score->\n",
            "DTC: 0.765789 (0.076376)\n",
            "model's accuracy score on the test data  : 0.6666666666666666\n",
            "K-fold cross validation score->\n",
            "RFT: 0.823684 (0.086116)\n",
            "model's accuracy score on the test data  : 0.8095238095238095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "pHi-fY2Ec6Kt",
        "outputId": "3a5a4b3c-d741-47e7-985c-eeb285916895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    action LR KNN SVM NB DTC RFT\n",
              "113      M  M   M   M  R   M   M\n",
              "23       R  R   R   R  R   M   R\n",
              "45       R  R   R   R  R   R   R\n",
              "81       R  M   M   M  M   R   M\n",
              "82       R  M   M   M  M   R   R\n",
              "109      M  M   M   M  M   R   R\n",
              "176      M  M   M   M  M   M   M\n",
              "134      M  M   M   M  M   M   M\n",
              "96       R  R   R   R  R   R   R\n",
              "98       M  M   R   R  M   R   M\n",
              "57       R  R   R   R  R   R   R\n",
              "169      M  M   M   M  R   R   M\n",
              "13       R  R   R   R  R   M   R\n",
              "204      M  M   M   M  R   M   M\n",
              "10       R  R   R   R  R   R   R\n",
              "161      M  M   M   M  M   M   M\n",
              "7        R  M   M   M  M   M   M\n",
              "172      M  M   M   M  R   M   M\n",
              "68       R  R   R   R  R   R   R\n",
              "102      M  R   M   M  M   M   M\n",
              "106      M  R   M   M  R   R   R"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4624a5a-3a7e-44c4-89c6-d61f9697a50d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>action</th>\n",
              "      <th>LR</th>\n",
              "      <th>KNN</th>\n",
              "      <th>SVM</th>\n",
              "      <th>NB</th>\n",
              "      <th>DTC</th>\n",
              "      <th>RFT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4624a5a-3a7e-44c4-89c6-d61f9697a50d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4624a5a-3a7e-44c4-89c6-d61f9697a50d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4624a5a-3a7e-44c4-89c6-d61f9697a50d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Algorithms\n",
        "from matplotlib import pyplot\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "fig.set_size_inches(8,6)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "WH61jGqdgLgi",
        "outputId": "1c579570-e350-4126-9608-13d030871425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results suggest that k-Nearest Neighbors, Support Vector Machines and Random Forest Tree  may be worth further study."
      ],
      "metadata": {
        "id": "xsEPucWj_OAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-NN algorithm Tuning"
      ],
      "metadata": {
        "id": "hTDmp4G5BF8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can start off by tuning the number of neighbors for KNN. The default number of neighbors is 7. Below we try all odd values of k from 1 to 21, covering the default value of 7. Each k value is evaluated using 10-fold cross validation on the training standardized dataset."
      ],
      "metadata": {
        "id": "uGkS9o1fEAsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN algorithm tuning\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
        "param_grid = dict(n_neighbors=neighbors)\n",
        "model = KNeighborsClassifier()\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10,n_jobs=-1)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Best accuracy : %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "ranks = grid_result.cv_results_['rank_test_score']\n",
        "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
        "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqS_-WuGBK_K",
        "outputId": "8ae6a468-933c-45f7-c179-d5f05c06e51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy : 0.849708 using {'n_neighbors': 1}\n",
            "#1 0.849708 (0.067279) with: {'n_neighbors': 1}\n",
            "#2 0.844444 (0.062244) with: {'n_neighbors': 3}\n",
            "#4 0.796199 (0.063526) with: {'n_neighbors': 5}\n",
            "#3 0.802339 (0.074561) with: {'n_neighbors': 7}\n",
            "#5 0.780409 (0.103067) with: {'n_neighbors': 9}\n",
            "#6 0.742398 (0.106132) with: {'n_neighbors': 11}\n",
            "#8 0.731871 (0.099862) with: {'n_neighbors': 13}\n",
            "#9 0.726608 (0.111290) with: {'n_neighbors': 15}\n",
            "#11 0.721345 (0.116769) with: {'n_neighbors': 17}\n",
            "#10 0.721930 (0.126878) with: {'n_neighbors': 19}\n",
            "#7 0.732456 (0.113917) with: {'n_neighbors': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning SVM"
      ],
      "metadata": {
        "id": "_Z0t4xINGD9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tune two key parameters of the SVM algorithm, the value of C (how much to relax the margin) and the type of kernel.\n",
        "\n",
        "\n",
        "The default for SVM (the SVC class) is to use the Radial Basis Function (RBF) kernel with a C value set to 1.0.\n",
        "\n",
        "\n",
        "Like with KNN, we will perform a grid search using 10-fold cross validation with a standardized copy of the training dataset."
      ],
      "metadata": {
        "id": "8nHrpLkxGRcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM algorithm tuning\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "param_grid = dict(C=c_values, kernel=kernel_values)\n",
        "model = SVC()\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "ranks = grid_result.cv_results_['rank_test_score']\n",
        "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
        "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4qkZc-XGeME",
        "outputId": "6f338aef-f7dd-46eb-960d-d43e30523642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.876901 using {'C': 2.0, 'kernel': 'rbf'}\n",
            "#17 0.786257 (0.115016) with: {'C': 0.1, 'kernel': 'linear'}\n",
            "#39 0.588304 (0.046652) with: {'C': 0.1, 'kernel': 'poly'}\n",
            "#40 0.567251 (0.030917) with: {'C': 0.1, 'kernel': 'rbf'}\n",
            "#29 0.732456 (0.071374) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
            "#25 0.743275 (0.088174) with: {'C': 0.3, 'kernel': 'linear'}\n",
            "#21 0.749415 (0.077096) with: {'C': 0.3, 'kernel': 'poly'}\n",
            "#18 0.764327 (0.080270) with: {'C': 0.3, 'kernel': 'rbf'}\n",
            "#20 0.754678 (0.073780) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
            "#34 0.716374 (0.072312) with: {'C': 0.5, 'kernel': 'linear'}\n",
            "#8 0.802924 (0.087331) with: {'C': 0.5, 'kernel': 'poly'}\n",
            "#9 0.802339 (0.113247) with: {'C': 0.5, 'kernel': 'rbf'}\n",
            "#23 0.744444 (0.111120) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
            "#35 0.711404 (0.066831) with: {'C': 0.7, 'kernel': 'linear'}\n",
            "#7 0.803216 (0.107355) with: {'C': 0.7, 'kernel': 'poly'}\n",
            "#12 0.796784 (0.099941) with: {'C': 0.7, 'kernel': 'rbf'}\n",
            "#22 0.749415 (0.099106) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
            "#31 0.721930 (0.080952) with: {'C': 0.9, 'kernel': 'linear'}\n",
            "#10 0.797368 (0.092797) with: {'C': 0.9, 'kernel': 'poly'}\n",
            "#6 0.807602 (0.106191) with: {'C': 0.9, 'kernel': 'rbf'}\n",
            "#28 0.733626 (0.106558) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
            "#31 0.721930 (0.077045) with: {'C': 1.0, 'kernel': 'linear'}\n",
            "#13 0.792105 (0.091595) with: {'C': 1.0, 'kernel': 'poly'}\n",
            "#5 0.818129 (0.095510) with: {'C': 1.0, 'kernel': 'rbf'}\n",
            "#19 0.759942 (0.094299) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
            "#33 0.716959 (0.076871) with: {'C': 1.3, 'kernel': 'linear'}\n",
            "#14 0.786550 (0.084269) with: {'C': 1.3, 'kernel': 'poly'}\n",
            "#4 0.833918 (0.061748) with: {'C': 1.3, 'kernel': 'rbf'}\n",
            "#30 0.727778 (0.100480) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
            "#38 0.695906 (0.082734) with: {'C': 1.5, 'kernel': 'linear'}\n",
            "#14 0.786550 (0.084269) with: {'C': 1.5, 'kernel': 'poly'}\n",
            "#3 0.855556 (0.058658) with: {'C': 1.5, 'kernel': 'rbf'}\n",
            "#26 0.738596 (0.106203) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
            "#37 0.696199 (0.088934) with: {'C': 1.7, 'kernel': 'linear'}\n",
            "#14 0.786550 (0.080915) with: {'C': 1.7, 'kernel': 'poly'}\n",
            "#2 0.871637 (0.059816) with: {'C': 1.7, 'kernel': 'rbf'}\n",
            "#24 0.743860 (0.080770) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
            "#36 0.706725 (0.076707) with: {'C': 2.0, 'kernel': 'linear'}\n",
            "#10 0.797368 (0.079970) with: {'C': 2.0, 'kernel': 'poly'}\n",
            "#1 0.876901 (0.059299) with: {'C': 2.0, 'kernel': 'rbf'}\n",
            "#27 0.738304 (0.075790) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning Random Forest Tree"
      ],
      "metadata": {
        "id": "OWw0Ml5ONdYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest classifier algorithm tuning\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "n_estimators =[10,20,30,40,50]\n",
        "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
        "param_grid = dict(n_estimators=n_estimators,criterion=criterion)\n",
        "model = RandomForestClassifier()\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "ranks = grid_result.cv_results_['rank_test_score']\n",
        "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
        "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBeK1Hq_NVXN",
        "outputId": "d5898fad-eb33-473a-ad15-94c10664a6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.835088 using {'criterion': 'gini', 'n_estimators': 10}\n",
            "#1 0.835088 (0.079607) with: {'criterion': 'gini', 'n_estimators': 10}\n",
            "#4 0.818421 (0.097456) with: {'criterion': 'gini', 'n_estimators': 20}\n",
            "#10 0.802632 (0.081003) with: {'criterion': 'gini', 'n_estimators': 30}\n",
            "#6 0.813158 (0.071173) with: {'criterion': 'gini', 'n_estimators': 40}\n",
            "#8 0.808187 (0.078330) with: {'criterion': 'gini', 'n_estimators': 50}\n",
            "#9 0.807602 (0.090585) with: {'criterion': 'entropy', 'n_estimators': 10}\n",
            "#7 0.812573 (0.080380) with: {'criterion': 'entropy', 'n_estimators': 20}\n",
            "#5 0.817836 (0.080418) with: {'criterion': 'entropy', 'n_estimators': 30}\n",
            "#2 0.834795 (0.077275) with: {'criterion': 'entropy', 'n_estimators': 40}\n",
            "#3 0.829532 (0.080673) with: {'criterion': 'entropy', 'n_estimators': 50}\n",
            "#11 nan (nan) with: {'criterion': 'log_loss', 'n_estimators': 10}\n",
            "#12 nan (nan) with: {'criterion': 'log_loss', 'n_estimators': 20}\n",
            "#13 nan (nan) with: {'criterion': 'log_loss', 'n_estimators': 30}\n",
            "#14 nan (nan) with: {'criterion': 'log_loss', 'n_estimators': 40}\n",
            "#15 nan (nan) with: {'criterion': 'log_loss', 'n_estimators': 50}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "50 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
            "    criterion = CRITERIA_CLF[self.criterion](\n",
            "KeyError: 'log_loss'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.83508772 0.81842105 0.80263158 0.81315789 0.80818713 0.80760234\n",
            " 0.8125731  0.81783626 0.83479532 0.82953216        nan        nan\n",
            "        nan        nan        nan]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKLgrLOx8LQx"
      },
      "source": [
        "# Finalize Model based on selecting Best method"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traing model : SVM"
      ],
      "metadata": {
        "id": "Ws2cwH_1VW3r"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoM3FhQS8FAw"
      },
      "source": [
        "model = SVC(C=2.0,kernel='rbf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGomegF-8TPv",
        "outputId": "88963290-c62a-4c3b-b954-d81c0f849b0c"
      },
      "source": [
        "#training the Logistic Regression model with training data\n",
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2.0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "585vgP7b8vBn"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCBykEtO8pLi"
      },
      "source": [
        "#accuracy on training data\n",
        "#in most of the cases accuracy of training data will be more bcoz the model has already seen this training data and most of the times the accuracy of test data will be less\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score( Y_train,X_train_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50Wqy2Rc9nL1",
        "outputId": "8823343d-7c00-431f-993b-408c5ddbab10"
      },
      "source": [
        "print('Accuracy on training data : ', training_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data :  0.9411764705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCUZ6MuR9tOV"
      },
      "source": [
        "#accuracy on test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04AsqCrz99vU",
        "outputId": "2bcf426a-12ca-4eaf-a3a5-6ce43ef65d0d"
      },
      "source": [
        "print('Accuracy on test data : ', test_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data :  0.8095238095238095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKrIzmr8-K9s"
      },
      "source": [
        "Making a Predictive System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMp-UfOd-B7B",
        "outputId": "87224cd9-1cab-42bf-e5fb-3d85fb8f0bb6"
      },
      "source": [
        "input_data = (0.0307,0.0523,0.0653,0.0521,0.0611,0.0577,0.0665,0.0664,0.1460,0.2792,0.3877,0.4992,0.4981,0.4972,0.5607,0.7339,0.8230,0.9173,0.9975,0.9911,0.8240,0.6498,0.5980,0.4862,0.3150,0.1543,0.0989,0.0284,0.1008,0.2636,0.2694,0.2930,0.2925,0.3998,0.3660,0.3172,0.4609,0.4374,0.1820,0.3376,0.6202,0.4448,0.1863,0.1420,0.0589,0.0576,0.0672,0.0269,0.0245,0.0190,0.0063,0.0321,0.0189,0.0137,0.0277,0.0152,0.0052,0.0121,0.0124,0.0055)\n",
        "\n",
        "# changing the input_data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the np array as we are predicting for one instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1) # we have 1 row and unknown columns # -1 -> It simply means that it is an unknown dimension and we want numpy to figure it out\n",
        "\n",
        "prediction = model.predict(input_data_reshaped)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]=='R'): #prediction[0] means the first element of prediction\n",
        "  print('The object is a Rock')\n",
        "else:\n",
        "  print('The object is a mine')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['M']\n",
            "The object is a mine\n"
          ]
        }
      ]
    }
  ]
}